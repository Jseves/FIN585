{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0225864",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "**Fin 585**  \n",
    "**Diether**  \n",
    "**Problem Set**  \n",
    "**Momentum Portfolios**  \n",
    "\n",
    "**1 Overview**\n",
    "\n",
    "In this problem set you reproduce your second important empirical result in academic finance. Specifically, you reproduce and extend (the original sample was about 1963 to 1990) **the momentum effect** of Jegadeesh and Titman (1993) (see \"Returns to Buying Winners and Selling Losers: Implications for Stock Market Efficiency\"). This empirical result spawned a huge literature in academic finance, and has been a critical core strategy for quant hedge funds (and others) for the last 30 years. You will find out in the next couple of weeks that models like the CAPM can't explain this portfolio return pattern at all. \n",
    "\n",
    "Momentum portfolios are formed based on past returns. Specifically, momentum portfolios are most commonly formed based on the cumulative return from months $t-12$ to $t-2$ (you should use this past return window for your portfolios):\n",
    "$$\n",
    "r_{i,t-12:t-2} \\approx \\sum_{x=2}^{12} \\log(1+r_{i,t-x})\n",
    "$$\n",
    "Note, it's common practice to cumulate (or compound) the returns using the log approximation (as above). You certainly can do the following if you want (well, not for this problem set ... use log returns for the problem set):\n",
    "$$\n",
    "r_{i,t-12:t-2} = \\left[ \\prod_{x=2}^{12} \\bigl(1+r_{i,t-x} \\bigr) \\right]  - 1\n",
    "$$\n",
    "The log approximation was initially used because it was less computational intensive, and a little easier to program. It's not an issue now, but the convention stuck.  \n",
    "\n",
    "Data for this problem set are monthly observations for all stocks on the NYSE, AMEX, and Nasdaq from July of 1962 to September of 2024. You can download the data directly using the following link: [data ](https://diether.org/prephd/06-mstk_62-24.csv). There is also a link on *Learning Suite*. The data contain the following variables that you will need for the assignment:\n",
    "\n",
    "|Variable | Description                                              |\n",
    "|---------|----------------------------------------------------------|\n",
    "|permno   | stock identifier                                         |\n",
    "|caldt    | calendar date                                            |\n",
    "|ticker   | ticker symbol                                            |\n",
    "|prc      | stock price (not lagged, contemporaneous with returns)   |\n",
    "|me       | market equity (not lagged, contemporaneous with returns) |\n",
    "|ret      | monthly return                                           |\n",
    "|shr      | shares outstanding in 1000s                              |\n",
    "\n",
    "\n",
    "**2 Tasks**\n",
    "\n",
    "1. Form quintile based equal-weight momentum portfolios and report summary statistics (including a t-test of whether the average return is statistically different from zero for each portfolio). Note, you should exclude low price stocks from your portfolios (price below $5). We will discuss the code for creating the portfolio formation variable in the class before the assignment.\n",
    "\n",
    "2. Compute the average number of stocks that are in each portfolio.\n",
    "\n",
    "3. Add a spread portfolio (100% long portfolio 4 and 100% short portfolio 0 $\\leftarrow$ it's a zero cost long/short (L/S) portfolio) to your dataframe of equal-weight momentum portfolios and then compute the summary statistics.\n",
    "\n",
    "4. Form quintile based value-weight momentum portfolios and report summary statistics (including a t-test of whether the average return is statistically different from zero for each portfolio). You should once again have five portfolios. The only difference between your equal-weight and value-weight portfolios will be the weights. A value weight portfolio is defined as the following ($me$ refers to the market value of equity):\n",
    "$$\n",
    "r_{pt} = \\sum_{i=1}^{n} \\omega_{i}r_{it} = \\sum_{i=1}^{n} \\left(\\frac{me_{i,t-1}}{\\sum_{j=1}^{n} me_{j,t-1}} \\right) r_{it}\n",
    "$$\n",
    "Hint: think about splitting the formula into the following parts delineated by the parentheses:\n",
    "\\begin{align*}\n",
    "r_{pt} &= \\left( \\frac{1}{\\sum_{j=1}^{n} me_{j,t-1}} \\right) \\left( \\sum_{i=1}^{n} me_{i,t-1} r_{it}\n",
    "          \\right)\n",
    " \\end{align*}\n",
    "And then compute each part as a separate groupby. Finally, just multiple the resulting dataframes together and you will have computed the value-weight portfolio returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d854031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('06-mstk_62-24.csv',parse_dates=['caldt'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2b7c3a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<br>\n",
    "\n",
    "**3 Portfolio Formation Variable: $r_{t-12,t-2}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['logret'] = np.log(1 + df['ret'])\n",
    "df['mom'] = df.groupby('permno')['logret'].rolling(11,11).sum().reset_index(drop=True)\n",
    "df['mom'] = df.groupby('permno')['mom'].shift(2)\n",
    "\n",
    "df['prclag'] = df.groupby('permno')['prc'].shift()\n",
    "df['melag'] = df.groupby('permno')['me'].shift(1)\n",
    "\n",
    "df = df.query(\"mom == mom and prclag >= 5\").reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be29ba1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<br>\n",
    "\n",
    "**4 Create Portfolio Bins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bins'] = df.groupby('caldt')['mom'].transform(pd.qcut,5,labels=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eabc12",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<br>\n",
    "\n",
    "**5 Finish Portfolio Construction and do Tasks**\n",
    "\n",
    "**Task 1**\n",
    "\n",
    "Form quintile based equal-weight momentum portfolios and report summary statistics (including a t-test one the mean). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ew = df.groupby(['caldt','bins'])['ret'].mean().unstack(level='bins')*100\n",
    "ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56faf289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finance_byu.summarize import summary\n",
    "summary(ew).loc[['count','mean','std','tstat','pval']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f889ed",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "+ **Extra: renaming the portfolio columns**\n",
    "\n",
    "+ Can do it compactly with string formatter or an fstring.\n",
    "\n",
    "+ Numeric column names can be annoying to work with; I change them to p0, p1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b81d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ew = (df.groupby(['caldt','bins'])['ret'].mean().unstack(level='bins')\n",
    "      .rename('p{:.0f}'.format,axis='columns')*100)\n",
    "ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd93e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ew = (df.groupby(['caldt','bins'])['ret'].mean().unstack(level='bins')\n",
    "      .rename(lambda x: f'p{x:.0f}',axis='columns')*100)    \n",
    "ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcd081",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ew).loc[['count','mean','std','tstat','pval']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9065c8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<br>\n",
    "\n",
    "**Task 2**\n",
    "\n",
    "Compute the average number of stocks that are in each portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2da6c4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "(df.groupby(['caldt','bins'])['ret'].count().unstack(level='bins')\n",
    "      .rename('p{:.0f}'.format,axis='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b7e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby(['caldt','bins'])['ret'].count().unstack(level='bins')\n",
    "      .rename('p{:.0f}'.format,axis='columns')).mean().round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278ed178",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "<br>\n",
    "\n",
    "**Task 3**\n",
    "\n",
    "Add a spread portfolio that goes long portfolio 4 and short portfolio 0 $\\leftarrow$ it's a zero cost L/S portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404eac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ew['spread'] = ew['p4'] - ew['p0']\n",
    "\n",
    "summary(ew).loc[['count','mean','std','tstat']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f79a64",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "<br>\n",
    "\n",
    "**Task 4**\n",
    "\n",
    "Create value-weight momentum portfolios.\n",
    "\\begin{align*}\n",
    "r_{pt} &= \\sum_{i=1}^{n} \\left(\\frac{me_{i,t-1}}{\\sum_{j=1}^{n} me_{j,t-1}} \\right) r_{it} \\\\[1.05ex]\n",
    "       &= \\left( \\frac{1}{\\sum_{j=1}^{n} me_{j,t-1}} \\right) \\left( \\sum_{i=1}^{n} me_{i,t-1} r_{it}\n",
    "          \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb89057",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcapsum = df.groupby(['caldt','bins'])['melag'].sum()\n",
    "\n",
    "df['rme'] = df['ret']*df['melag']\n",
    "vw = df.groupby(['caldt','bins'])['rme'].sum() / mcapsum\n",
    "vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b885f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "vw = vw.unstack(level='bins').rename('p{:.0f}'.format,axis='columns')*100\n",
    "vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vw['spread'] = vw['p4'] - vw['p0']\n",
    "summary(vw).loc[['count','mean','std','tstat','pval']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c73878",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "<br>\n",
    "\n",
    "**6. Alternate Value-Weighting Method**\n",
    "\n",
    "+ Conceptually straight forward, but relatively slow execution.\n",
    "\n",
    "+ Write a function using the logic of the way the value-weight formula is normally written.\n",
    "\\begin{align*}\n",
    "r_{pt} &= \\sum_{i=1}^{n} \\left(\\frac{me_{i,t-1}}{\\sum_{j=1}^{n} me_{j,t-1}} \\right) r_{it}\n",
    "\\end{align*}\n",
    "\n",
    "+ Logic $\\rightarrow$ compute the weights, multiple the weights and returns together, and then sum everything up. $\\leftarrow$ this function is called by the `groupby`.\n",
    "\n",
    "+ The function in this case will have a close correspondence with the way we most naturally write the portfolio return formula.\n",
    "\n",
    "+ Coding note: need to use `apply` with the `groupby` instead of `transform` or `aggregate`.\n",
    "\n",
    "  - Why? Sending in an Nx2 dataframe (need returns and lagged market-cap) and then for each date/bin group we are going to return a scalar portfolio return (1x1).\n",
    "\n",
    "  - It's a type of aggregation but the `aggregate` method expects an Nx1 vector and returns a 1x1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def vw_port(x):\n",
    "    wtotal = x['melag'].sum()\n",
    "    return ((x['melag']/wtotal)*x['ret']).sum()\n",
    "\n",
    "vw = df.groupby(['caldt','bins'])[['ret','melag']].progress_apply(vw_port)\n",
    "vw = vw.unstack(level='bins')*100\n",
    "vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(vw).loc[['count','mean','std','tstat','pval']].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a035b",
   "metadata": {
    "cell_marker": "r\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "<br>\n",
    "\n",
    "**7 A Little Speed Testing**\n",
    "\n",
    "+ The Jupyter notebook environment contain a special function for testing the speed of code $\\rightarrow$ `%timeit`\n",
    "\n",
    "+ In a normal Python environment, you can use the `time` module.\n",
    "\n",
    "+ But given we're using a notebook, so let's use `%timeit` to compare the speed of the two approaches for creating value-weight portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f6899",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def vw_one():\n",
    "    df['rme'] = df['ret']*df['melag']\n",
    "    vw = df.groupby(['caldt','bins'])['rme'].sum() / df.groupby(['caldt','bins'])['melag'].sum()\n",
    "    \n",
    "%timeit -n 1 -r 3 vw_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac48f4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def vw_two():\n",
    "    vw = df.groupby(['caldt','bins'])[['ret','melag']].apply(vw_port)\n",
    "\n",
    "%timeit -n 1 -r 3 vw_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855b7fcb",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "<br>\n",
    "\n",
    "**7.1 Why is the First Approach Faster?**\n",
    "\n",
    "+ The first approach is more efficient (fast) because it relies solely on native `pandas'` methods.\n",
    "\n",
    "+ Relying as much as you can on built in Pandas' methods will generally result in faster code.\n",
    "\n",
    "+ The speed advantage comes from the built in methods and functions being written in the `C` programming language.\n",
    "\n",
    "+ Technically most of `pandas'` functions and methods are written in a language called `Cython`. It is easy to convert `Cython` into `C`.\n",
    "\n",
    "+ When you supply a custom function to `Pandas` (even a simple one like `vw_weight`), `Pandas` usually has to execute more of the process in `Python` rather than `C`.\n",
    "\n",
    "+ Also, any operations you can compute on a whole column at once rather than as part of a function called by a `groupby` will be faster (we did that with one operation above).<br><br>\n",
    "\n",
    "\n",
    "**7.2 Extra: Using the Time Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "for r in range(3): vw_one()\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Average execution: {(end_time-start_time)/3:.3f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e78fe2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}